{
  "address": "",
  "chat": "https://huggingface.co/second-state/Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf",
  "chat_ctx_size": "4096",
  "description": "Llama-3-8b-Instruct",
  "domain": "gaianet.network",
  "embedding": "https://huggingface.co/second-state/All-MiniLM-L6-v2-Embedding-GGUF/resolve/main/all-MiniLM-L6-v2-ggml-model-f16.gguf",
  "embedding_ctx_size": "384",
  "llamaedge_port": "8080",
  "prompt_template": "llama-3-chat",
  "rag_prompt": "Use the following pieces of context to answer the user's question.\n----------------\n",
  "reverse_prompt": "",
  "snapshot": "https://huggingface.co/datasets/gaianet/none/resolve/main/none.snapshot",
  "system_prompt": "You are a helpful, respectful, and honest assistant."
}
